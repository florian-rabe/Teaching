\section{Process Aspects}

This section collects general methods that have been developed by practitioners to get a better handle on managing the software engineering process.

They are generally very cheap and easy to deploy.
Therefore, it should\footnote{It is not, though.} be considered gross\footnote{\emph{Gross} negligence is the kind that makes people liable to prosecution or litigation.} negligence to develop dependency-critical software without any one of these.

However, training lacks behind with many current developers not updated on latest technologies.

\subsection{Coding Style}
  
There are many aspects of a program that have no semantic relevance.
These include
\begin{compactitem}
 \item most whitespace including
   \begin{compactitem}
    \item indentation and vertical alignment
    \item tabs vs. spaces
    \item placement of opening and closing brackets
    \item optional spaces between operators and arguments
   \end{compactitem}
  \item choice of names for any names that are not fixed in the specification of the interface
    \begin{compactitem}
     \item private methods and field of a class
     \item local variables of a function
     \item classes and similar units that are not part of the specification
    \end{compactitem}
  \item syntactic restrictions on names including
   \begin{compactitem}
     \item length of names (documenting effect vs. readability)
     \item capitalization of first character (e.g., lower case for values, upper case for types)
     \item capitalization of inner characters (e.g., camel case vs. underscores)
   \end{compactitem}
  \item syntactic restrictions on declarations including
   \begin{compactitem}
     \item length of a method
     \item number of declarations in a class
     \item order of declarations (e.g., public vs. private, values vs. methods, mutable vs. immutable)
   \end{compactitem}
  \item preferred methods when multiple options are available, e.g.,
   \begin{compactitem}
     \item $l.nonEmpty$ vs. $!l.isEmpty$
     \item $a.getX()$ vs. $a.getX$ if the compilers allows both
     \item placement of optional semicolons
     \item spelling out the argument or return types of a function when the compiler can infer them
   \end{compactitem}  
  \item formatting of structured documentation including
   \begin{compactitem}
     \item placement of documentation inside the comment
     \item use of markdown syntax inside comments
     \item presence and order of keywords (e.g., author, param, return)
   \end{compactitem}
   \item placement and formatting of comments containing verification-relevant information including
   \begin{compactitem}
     \item pre/postconditions of methods
     \item class invariants
     \item loop invariants
     \item termination orderings for loops and recursive functions
   \end{compactitem}
\end{compactitem}
  
By standardizing these across a large project, readability is greatly enhanced.
This is particularly important when it happens frequently that
\begin{compactitem}
 \item new programmers join a team and have to be quickly retrained on the entire code base
 \item programmers move between teams
 \item different teams work on the same code
\end{compactitem}

Style checkers can be standalone or integrated into an IDE.
Either way, they allow customizing a style and enforcing it throughout a project.

Modern IDEs (e.g., IntelliJ) provide a wide variety of coding style configurations whose violation results in special warning.
  
\subsection{Documentation}

Thorough documentation is used for multiple purposes:
\begin{compactitem}
 \item tie the implementation to the specification (e.g., by referencing the exact page or item of the specification corresponding to a declaration)
 \item inform other programmers about functionality and important subtleties
 \item provide examples for how to instantiate a class or call a function
 \item automatically extract web pages containing API documentation
 \item attach verification-relevant information that can be automatically extracted by verifiers
\end{compactitem}

Most programming languages come with supporting tools that allow for structured documentation. 
For example, Javadoc is a structured documentation language for Java.
The following example snippet is taken from the Javadoc home page:

\begin{lstlisting}
/**
 * Returns an Image object that can then be painted on the screen. 
 * The url argument must specify an absolute {@link URL}. The name
 * argument is a specifier that is relative to the url argument. 
 * <p>
 * This method always returns immediately, whether or not the 
 * image exists. When this applet attempts to draw the image on
 * the screen, the data will be loaded. The graphics primitives 
 * that draw the image will incrementally paint on the screen. 
 *
 * @param  url  an absolute URL giving the base location of the image
 * @param  name the location of the image, relative to the url argument
 * @return      the image at the specified URL
 * @see         Image
 */
 public Image getImage(URL url, String name) {
        try {
            return getImage(new URL(url, name));
        } catch (MalformedURLException e) {
            return null;
        }
 }
\end{lstlisting}

Note how it
\begin{compactitem}
 \item uses \lstinline|/**| instead of the usual \lstinline|/*| to indicate a structured comment
 \item can link to other code parts (which requires some compilation knowledge to resolve relative references in the documentation)
 \item integrates HTML which is carried through to the generated web pages
 \item uses keywords like \lstinline|@param| so that better web pages can be produced
 \item is connected to the code by repeating the names of the function variables (which can be flagged by the style checker)
\end{compactitem}

\subsection{Versioning}

Sophisticated version management systems like svn and recently git have tremendously improved the development process.
Specifically, the use of git for the Linux kernel and the success of github have made a huge impact in the open source community.

They allow
\begin{compactitem}
 \item collaboration across physical distances
 \item maintaining different version of a software (e.g., a release and a development branch)
 \item using commit messages to log and communicate the reason and effect of a change
 \item retroactively determining when and by whom a bug was introduced
 \item automated building and testing on every commit
\end{compactitem}

The following article about google repository management is particularly interesting:
\url{http://cacm.acm.org/magazines/2016/7/204032-why-google-stores-billions-of-lines-of-code-in-a-single-repository/fulltext}

\subsection{Backups}

\footnote{This was not part of the course.}

\subsection{Code Review}

Code review is the process of programmers reviewing each other's code before (or sometimes after) it becomes part of the stable parts of the code base.

Many modern versioning tools simplify the process by
\begin{compactitem}
 \item reifying changes (e.g., as diffs/patches or commits) so that each change can be reviewed and applied individually
 \item managing the available changes and applying them to branches
 \item maintain the proposed changes and the feedbacks and decisions by the reviewer
\end{compactitem}

Github's maintenance of git pull requests is a simple example of a systematic code review process.

\subsection{Automated Building and Testing}

Most commit-based software repositories allow for hooks that are executed automatically before or after every commit (called push in git).

This is typically used for testing.
A typical commit hook should
\begin{compactitem}
 \item create a fresh checkout of the source code
 \item build the source
 \item run a test suite (where the test may be part of the source or provided externally)
\end{compactitem}

For most repository managers, automated build managers exist.
They can generate reports for every commit and, e.g., alert users by emails upon new commits that fail the tests.
A pre-commit hook can even reject the commit if the test failed.

travis is a typical example.
It is well-integrated with, e.g., github.

\subsection{Issue-Tracking}

Issue tracking is the systematic management of known problems, their discussion, and eventual solution.
Usually an issue is maintained as a discussion thread, and all open issues are available in a list that allows for filtering and sorting.
They are typically provided via web interfaces, in particular to allow users to easily submit issues.

The typical process is
\begin{compactenum}
 \item The initial post \textbf{opens} the issue.
 \item After some discussion, the issue is \textbf{assigned} to a programmer or team.
 \item After posting and checking the solution, the issue is \textbf{closed}.
\end{compactenum}

There is a wide variety of issue tracking systems, usually independent of the programming language.
Many are integrated with wikis or versioned repositories.
Examples are trac and github.

\section{Programming Aspects}

This section collects mostly independent practices for individual aspects of programming.

\subsection{Input Validation and Internal Syntax}

The following is a fundamental principle that is absolutely necessary when handling user input:
\begin{compactitem}
 \item There is a data structure that represents the input/external syntax.
 This data structure is called the internal syntax.
 It should exactly follow the grammar of the input language.\footnote{Incidentally, this means that untyped languages are out}
 \item All processing proceeds in the following steps:
 \begin{enumerate}
 \item User input is parsed from a string holding external syntax into an object of type of the internal syntax.
  The parser must be side-effect-free: It does not nothing but parse and return an object of the internal syntax or an error message.
  Failure results in immediately rejecting the user input.
  \item All processing that ever happens works with the internal syntax.
  External syntax is never visible to any other function than the parser.
  \item The data structure provides a printer (also called serializer) that turns it into a string.
  Any output that is to be displayed to the user is generated in this way.
 \end{enumerate}
\end{compactitem}

It is desirable that parser and printer are exactly inverse to each other.
However, it is common that certain aspects of the internal syntax are lost after parsing and printing (e.g., whitespace).
However, no meaningful information should be lost, e.g., the parser should not insert default value for omitted optional arguments---instead, it must record that the argument was omitted.

Conversely, parsing followed by printing must succeed and must result in the original object.
Thus, we must have $parse(print(i))=i$ and ideally also $print(parse(e))=e$.
 
\subsection{Common Bugs}\label{sec:sd:commonbugs}

We know that correctness is undecidable.
But that is irrelevant for a pragmatic approach: the more can be avoided, the better.

Therefore, much work has gone into training programmers to avoid or build static analysis tools (see Sect.~\ref{sec:sd:static}) to spot common bugs.
The following gives some examples of frequent bugs that can be systematically avoided.
Note that some avoidance strategies are hypothetical, that is, not every programming language supports the respective feature.

\paragraph{Array and List Bounds}
When iterating over an array or a list, we often use for-loops with an integer variable that runs from $0$ to $n-1$, where $n$ is the length.
Getting the index bounds wrong is a common mistake.

A good solution is to avoid the use of loops that only count up index variables.
Instead, we can use $map$ or $foreach$ operations that traverse a list.

For example, to shift all values in $x$ one up, we can use a counter with subtle traps 
\begin{acode}
\afor{i}{1}{x.length-1}{
 x[i-1]:=x[i]
}\\
x[x.length-1]:=0
\end{acode}

A better solution is to use language constructs that enforce the correctness such as traversal operators on traversable data structures:
\begin{acode}
x.indices.tail\;foreach\;i =>\ablock{
 x[i-1]:=x[i]
}\\
x[-1]:=0
\end{acode}
Here our knowledge about the methods $indices$ and $tail$ guarantee that the assingment is only executed for indices of elements that have an element before them---no fiddling with the bounds of the for-loop is needed.
Moreover, the last assignment uses modular arithmetic to access the last element without fiddling with the length.

\paragraph{Buffer Bounds}
Buffers can be treated as special arrays.
The same techniques apply.

A particularly insane (and useless) property of buffers in certain low level programming languages is that the length of the buffer can be fixed in memory but not fixed in the programming language.
Thus, after creating a buffer of size $n$, we can overread from it, i.e., read $m>n$ values from it.
In this case, a C-like language will happily read whatever resides in memory after the buffer.

That can easily be avoided by
\begin{compactitem}
 \item using high-level data structures that hide the memory allocation from users of the data structure,
 \item or (even better) using high-level programming languages that hide the memory allocation from the programmer entirely.
\end{compactitem}
In the latter case, buffer overreads are at least run-time exceptions.

\paragraph{Null Pointers}
Null pointers are routinely used by bad programmers, especially in bad programming languages.
It is best not to use $null$ at all.
Indeed, good programmers program as if $null$ does not exist.

A better solution is to use language constructs that enforce the correctness: the option type
\begin{acode}
\adata{Option[A]}{Some(value:A),None}
\end{acode}
which provides an explicit value for absent values.
Now every access to $x:Option[A]$ has to say what to for each of the two possible cases.

The only exception is when calling an external library that uses $null$.
But even in that case, it is best to use back-and-forth translations between possibly-null and option values:
\begin{acode}
\afun[{Option[A]}]{fromMaybeNull[A]}{x:A}{
  \aifelse{x==null}{None}{Some(x)}
}\\
\afun[A]{toMaybeNull[A]}{x:Option[A]}{
  x.getOrElse(null)
}
\end{acode}

\paragraph{Casting}
Every type cast $\aasinst{x}{B}$ of a value $x$ to type $B$ must be investigated for its correctness.
That includes 
\begin{compactitem}
 \item plausibility: is $B$ a subtype of $A$---if not, the cast is definitely a bug and can be flagged by the compiler
 \item correctness: is $x$ guaranteed to have type $B$---that requires a complex argument.
\end{compactitem}

Such casts are typically guarded as in
\begin{acode}
\aifelse{\aisinst{x}{B}}{f(\aasinst{x}{B})}{g(x)}
\end{acode}

A better solution is to use language constructs that enforce the correctness.
One way to do this is a case-distinction operator
\begin{acode}
\amatch{x}{\acase{x:B}{f(x)}, \acase{\_}{g(x)}}
\end{acode}
which allows the compiler to spot a missing case if the second case is forgotten.

An even simpler solution is to use a cast operator that returns an options value:
\begin{acode}
\afun[{Option[B]}]{optCast}{x:A}{\ldots}\\
(optCast(x)\; map\; f).getOrElse(g(x))
\end{acode}

\paragraph{Uninitialized Memory}
Some programming languages allow introducing names without initial values.
Those can be variables or (in C-like low-level languages) memory areas.

Uninitialized variables can easily be spotted by analysis tools.
They should not be warnings but actual compiler bugs.
Allowing them at all is a design flaw of the programming language.

A variant of uninitialized variables are variables initialized with $null$.
That is equally easy to spot and equally forbidden.

Uninitialized memory areas are occasionally useful when initializing a large memory area is considered too costly.
In most cases, this can be avoided entirely by using good data structures.


\subsection{Safe by Design}

This section collects a few implementation principles that help minimize the likely hood of errors.

\paragraph{Safe Defaults}
Default and initial values should always be chosen in such a way that they lead to the minimal possible behavior.

For example, a security check should be wrapped in an exception handler that treats every exception as failure of the check.

\paragraph{Minimal Access Rights}
Any component $C$ that needs access to critical shared component $D$ should have only the minimal access rights needed for its correct operation.

For example, if $C$ is a program and $D$ is a database or file system, then $D$ should provide an interface that allows only exactly those write operations that $C$ needs.
If $C$ has to write to a specific table $T$ in a specific database, we write add a wrapper around $D$ to the source code base of $C$.
This wrapper includes a specific function $f$ that makes exactly the changes to $T$ that $C$ needs to trigger.
$C$ will call only call $f$ and will have no access to $T$ or $D$ as a whole.

\paragraph{Minimal Interfaces}
All classes $D$ should only make those methods public that are needed by the other classes $C$ using them.
Methods that are not needed by any $C$ are made private in $D$.

Vice versa, a class $C$ should only have access to methods of $D$ if it actually has to call them.
Methods of $D$ that are not needed by $C$ are made invisible by introducing an abstract interface $I$.
$I$ declares exactly the methods needed by $C$, $D$ implements $I$, and $C$ uses $I$ instead of $D$.

\subsection{Using Libraries}

\footnote{This was not part of the course.}

\section{Stability}

Frequent changes are extremely dangerous to even the best software development process.

Stability is particularly important for
\begin{compactitem}
  \item the specification,
  \item the design of the data structures and algorithms,
  \item the project team,
  \item the coding style,
  \item the workflows for building, committing, etc.,
  \item the policies for access, review, and approval of changes.
\end{compactitem}

It is very tempting for managers, marketing department, and customers to request changes because they seem easy to them.
Even many programmers often underestimate their dangers.

But every change at a high level introduces lots of increasingly greater and more expensive changes at lower levels.
Eventually, the lower levels (especially when resources are tight, which is always the case) have to introduce workarounds, hacks, and special-case treatments to handle the changes.

To the top-level person who requested the change, everything looks fine because the lower levels will usually do a good job of hiding the mess.
But below the surface the codebase will become increasingly messy until it is unmanageable.
In particular, any deep dependability analysis (e.g., a formal correctness proof) may become so difficult that it is practically impossible.

A good metaphor is to think of a long stick representing the hierarchy.
The person at the top points the stick at a slightly different angle, which does not very different from the top.
But at the lower end of the stick, the small change in angle caused a massive shift of the end of the stick.
The shift may be much bigger than what the inertia of the stick allows, and the sticks breaks somewhere in the middle.
When the stick breaks, the people at the breaking point in the middle move the lower half of the stick so that it points to the right point and hire two new people $A$ and $B$.
$A$ constantly measures the movement of the upper half of the stick and shouts the values to $B$.
$B$ then computes how much the lower half would move if the halves were still connected and moves the lower half accordingly.
The person at the top does not notice anything.
But over time, the stick has broken into many pieces, and lots of people are in charge of pretending it is still one piece.


\section{Choice of Programming Language}

The choice of programming language can have major implications for dependability.
We discuss some evaluation criteria for programming languages.

\paragraph{Learnability}
A programming language should be easy to learn.
Properties that support this are:
\begin{compactitem}
\item a simple, elegant language constructs, whose meaning is close to human or mathematical intuition,
\item a concrete syntax that makes the structure of programs apparent without introducing overhead
\item a coherent design that avoids special case treatment as much as possible
\item built-in (or automatically imported from the standard library) data structures for common concepts such as strings, lists, options, functions, dictionaries along with simple concrete syntax for them
\item a simple hello-world with minimal overhead
\item an interactive interpreter that allows experimenting
\item easily-installable IDE plugins and command-line compilers/interpreters
\end{compactitem}

Easy-to-learn languages support dependability because
\begin{compactitem}
 \item They guarantee a steady stream of competent programmers.
 \item They allow programmers to focus on the domain knowledge and the system rather than being distracted by language issues.
\end{compactitem}

\paragraph{Tool Support}
A programming language should come with a variety of tools including compiler, interpreter, interactive interpreter, IDEs, and dynamic and static analysis tools.
Programming languages are in principle independent of the tool support: any language can offer any tool.
For example, any language can be compiled or interpreted.
However, in practice languages tend to come with a single implementation and at most a small set of third-party tools.

In particular, dynamic and static analysis tools is critical for dependability.
Compiled languages are preferable because
\begin{compactitem}
 \item the compiler performs fundamental static analysis, which includes at least in particular scope- and type-checking
 \item additional static analysis tools can be easily implemented on top of the compiler
\end{compactitem}

\paragraph{Availability of Skilled Programmers}
Any major software project needs multiple programmers over a long time.
Therefore, it is indispensable to have a large supply of competent programmers.

This can be achieved by retraining programmers (see Learnability).
Indeed, most programmers can easily learn a new language.
But sometimes the choice of language can affect the set of available programmers:
\begin{compactitem}
 \item Existing people may be committed to one language and be unwilling to switch.
 \item Potential hires might not be interested in job openings due to their personal language preferences.
\end{compactitem}

\paragraph{Availability of Libraries}
Anticipating and surveying needed libraries is critical.
Besides the obvious criterion of dependability, this includes judging libraries based on appropriateness\footnote{A common mistake is to assume a library will work well without assessing the overhead cost of adapting to it.}, maturity, active support, and license.

Some commonly-used advanced data structures such as for hash tables, heaps, etc. are needed in every project.
These should be provided by a mature and well-designed standard library and possibly some auxiliary libraries.
Moreover, projects may require libraries for networking, parsing, cryptography, XML etc.

Additionally, many projects require the implementation of large amounts of domain-specific knowledge.
Often these libraries are written by domain experts and are available for whichever programming language that expert happened to like.
Therefore, programming languages may differ widely in the available library support.

If needed libraries are not available, they must be provided in-house.
That is a frequent source of faults.

\paragraph{Existing Codebases}
Most projects are not started in a vacuum but must interact with existing code.
The cost of using different programming languages must be assessed in a project-specific way.

Changing to a different language requires not only reimplementing not only programs but also redesigning work flows and relearning tools.
This may alienate programmers and render useless institutional memory that has accumulated for years.
Moreover, small changes in the reimplementation can introduce subtle faults.

Adding a new programming language to an environment introduces an abrupt interface between components.
Some programming languages allow direct compatibility using foreign-function interfaces (often to C) or by compiling to the same virtual machine (often for the JVM).
But often the interface requires text-based communication between these components (e.g., using strings or files), which is a common source of faults.
Modern data exchange languages like JSON, XML, or protobuffers have improved the situation somewhat but are still much worse than direct compatibility.
In any case, unless the separation into components perfectly matches the a logical separation in the design of the software, it leads to design flaws that make the software harder to understand, use, debug, and verify.

In either scenario, the likelihood of faults increases.

\paragraph{Efficiency}
A programming language should produce efficient programs and allow programmers to optimize their programs.
Generally, low-level, hardware-near programming language (like imperative languages, especially the C family) are more efficient than high-level, specification-near ones (like functional languages).

Efficiency contributes little to dependability though.
An exception arises when workarounds (e.g., a foreign-function interface to C or a shell-call to a different program) must be introduced to meet efficiency targets that cannot be elegantly met by the otherwise-preferred solution.

\paragraph{Specification-Nearness}
Most elusively, a programming language should allow for implementations that are as close to the domain knowledge as possible.
That allows
\begin{compactitem}
 \item domain experts to program or verify the programs themselves, thus increasing the likelihood of correctness
 \item understanding and verifying programs more easily
\end{compactitem}
This requires high-level programming languages with sophisticated support for defining data types such as inductive data types from functional or class hierarchies from object-oriented languages.

Ideally, this would be the most important criterion to obtain dependable software.
However, it tends to be mutually exclusive with the other criteria:
Good high-level languages tend to be younger and therefore have fewer programmers, tool support, libraries and existing codebases.
The emphasis on high-level concepts makes them less hardware-near and thus less efficient and more mathematical and thus harder to learn.

\section{Programming Language Design}

\footnote{This section was added after presenting the part on formal methods and collects some lessons that were learned in those lectures.}

There are a number of programming language features that are tremendously important for building dependable software.
Their common property is to restrict the possible programs that can be written to ensure that only good programs can be written.
This puts an additional burden on the programmer, who now has to take care to stay inside the restricted set.

Unfortunately, most modern mainstream programming languages are not designed optimally because they do not enforce these restrictions.
There are multiple reasons for that:
\begin{itemize}
\item The true benefit of these restrictions only becomes apparent when formally reasoning about the correctness of programs (see Part~\ref{sec:sd:fm}).
  That does not happen very often (yet).
\item Programming languages evolve slowly, and the design of mainstream languages can be decades behind the state of the art.
\item Self-taught or inexperienced programmers do not understand the restrictions and are unable to see their value, which makes them prefer the simpler unrestricted languages.
\end{itemize}

When programming in unrestricted languages, it is still good practice for a programmer to stay within a reasonably restricted fragment.
Without support from the compiler, this can be very tedious.

Much safety-critical software is written in restricted fragments of unrestricted languages, where the restrictions are spelled out explicitly and checked by separate tools.
The fragment of C without pointer arithmetic is a commonly-used example.

\subsection{Typing}

By far the most important restriction is typing: all functions and terms are typed, and only well-typed programs are allowed.
This allows the compiler to statically check well-typedness so that errors are caught at compile-time instead of run-time.

This restriction forbids a number of error-prone features such as reflection and C-style pointer arithmetic.

This is discussed in depth in Ch.~\ref{sec:sd:static} and Part.~\ref{sec:sd:fs}.

\subsection{Mutable-Immutable Distinction}

Programming languages can easily force a distinction between mutable and immutable variable declarations.
The former may be assigned to, the latter are never assigned and permanently retain their initial value.

Immutable variables are also called \textbf{values} because they are abbreviations for a given value.

In practice, the majority of variables are never assigned to.
Moreover, mutable variables present much bigger difficulties for formal methods.
Therefore, it is desirable to minimize the number of mutable variables and maximize the number of immutable ones.

That is possible if the programming language provides two different ways to declare variables (e.g., $\aval{x}{\Int}{0}$ and $\amval{x}{\Int}{0}$) and forbids assignments to immutable variables.

\subsection{Command-Query Separation}

A \textbf{command} is a function that has a side effect, i.e., an assignment to a global variable or an I/O-operation.
A \textbf{query} is a function that returns a value.

In general, a function may bo both.
Command-query separation is the principle that a function should either have a side effect or return a value.

Due to the lack of side effects, queries are much easier to reason about than commands.
Therefore, it is desirable to minimize the number of commands and maximize the number of queries.

That is possible if the programming language provides two different ways to declare function and forbids side effects inside queries.

However, there are many practical examples of functions that are naturally both a command and a query.
These include opening a file, logging (e.g., for debugging) inside a query, statistics about how often a function was called, or the pop method of a mutable stack class.

Therefore, programming language do not enforce command-query separation.
Erlang is a notable exception.

\subsection{Private Fields}

Instances of classes are often around for a long time, e.g., throughout the duration of the program.
Moreover, they tend to be global in the sense that many parts of the program can access them.

That makes it difficult to break down reasoning about the entire program to independent reasoning about the program components.

Therefore, the public interface of a class should be as small as possible.
More precisely, the number of methods that may modify the mutable fields should be minimal.

A simple step towards supporting that is for programming languages to require that all mutable fields be private.
Moreover, all methods can be private by default so that programmers must explicitly make a method available.

\subsection{Isolated Side Effects}

Side generally are generally very hard to reason about.
Therefore, it is desirable to allow them only in specific positions.

Typical positions where side effects should be forbidden are the conditions in if and while commands, the arguments of built-in operators such as $+$, or the argument of the print command.

However, it is difficult to enforce this restriction because it is undecidable whether a piece of code as side effects.
One solution may be to over-approximate by using a decidable set of expressions that may (but not necessarily will) have side effects.