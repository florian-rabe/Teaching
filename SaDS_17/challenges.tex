This chapter lists examples of disasters and failures that serve as examples of what secure and dependable systems should avoid.

The lists are not complete and may be biased by whether
\begin{compactitem}
 \item I became aware of it and found it interesting enough
 \item the cause could be determined and was made public
\end{compactitem}
Feel free to edit these notes by adding important examples that I forgot when I compiled the lists.

All damage estimates are relative to the time of the event and not adjusted to inflation.

Note that for security problems, the size of the damage is naturally unknown because attacks will typically remain secret.
Only the cost of updating the systems can be estimated, which may or may not be indicative of the severity of the security problem.

\section{General Aspects}

\highlightframe{
State-of-the-art software and hardware systems simply are not safe, secure, and dependable.

Moreover, we do not understand very well yet how to make them so.
}

This is different from many other areas such as mechanical or chemical engineering.
While these occasionally cause disasters, these can usually be traced back to human error, foul play, or negligent or intentional violation of regulations.
Such disasters usually result in criminal proceedings, civil litigation, or revision or extension of regulations.
% what engineers know and how they know it

The situation is very different for computer systems.
There is no general methodology for designing and operating computer systems well that can be easily described, taught, or codified.

The situation will hopefully improve over the course of the 21st century.
The problem has been recognized decades ago, and many companies and researchers are working on it.
They approach from very different directions with different goals and different methodologies.

\highlightframe{
This has resulted in a wide and diverse variety of not coherently connected methods with varying degrees of depth, maturity, cost, benefit, and practical adoption.
}

A typical effect is a trade-off along a spectrum of methods:
\begin{compactitem}
 \item cheap but weak methods on one end
 \item strong but expensive methods on the other end.
\end{compactitem}
Therefore, it is often necessary to choose a degree of safety assurance rather than actually guarantee safety.
This spectrum is so extreme that
\begin{compactitem}
 \item the majority of practical software development does not systematically ensure any kind of safety,
 \item the majority of theoretical solutions are neither ready nor affordable for practical use.
\end{compactitem}

Incidentally, this means that this course's subject matter is much less well-defined than that of other courses.%
\footnote{For example, the other two courses in this module almost design themselves because the subject matter is very well understood and standardized.}
That makes it particular difficult to design a syllabus for.
It will give an overview of the most important state-of-the-art methods.

\section{Major Disasters Caused by Programming Errors}

\paragraph{Space Exploration}
There have been a number of failures in space exploration due to minor programming errors.
These include
\begin{compactitem}
 \item 1962, Mariner 1 rocket lost: misread specification (overlooked bar over a variable) was implemented (damage around \$$20$ million)
 \item 1982, Viking I lost: software update written to wrong memory area overriding vital parameters for antenna
 \item 1988, Phobos 1 lost: one character missing in software update led to accidentally executing a testing routing at the wrong time
 \item 1996, Mars Global Surveyor lost: data written to wrong memory addresses
 \item 1999, Mars Polar Lander lost: presumably software not accounting for false positive when detecting shutdown even though the possibility was known
 \item 2004, Mars Rover Spirit lost for 16 days: delay in deleting obsolete files led to lack of available flash memory, which triggered a reboot, which led to a reboot cycle
\end{compactitem}
% the story of a Fortran bug where . was accidentally written instead of a , appears to be exaaggerated; it did not lead to a crash

\paragraph{Therac-25}
Between 1985 and 1987, the Therac-25 machine for medical radiation therapy caused death and/or serious injury in at least $6$ cases.
Patients received a radiation overdose because the high intensity energy beam was administered while using the protection meant for the low intensity beam.

The cause was that the hardware protection was discontinued, relying exclusively on software to prevent a mismatch of beam and protection configuration.
But the software had always been buggy due to a systemic failures in the software engineering process including complex systems (code written in assembly, machine had its own OS), lack of software review, insufficient testing (overall system could not be tested), bad documentation (error codes were not documented), and bad user interface (critical safety errors could be manually overridden, thus effectively being warnings).

Details: \url{https://en.wikipedia.org/wiki/Therac-25}

\paragraph{Patriot Rounding Error}
In 1991 during the Gulf war, a US Patriot anti-missile battery failed to track an incoming Iraqi Scud missile resulting the death of 28 people.

The cause was a rounding error in the floating point computation used for analyzing the missile's path.
The software had to divide a large integer (number of $0.1s$ clock cycles since boot $100$ hours ago) by $10$ to obtain the time.
This was done using a floating-point multiplication by $0.1$---but $0.1$ is off by around $0.000000095$ when chopped to a $24$-bits binary float.
The resulting time was off by $0.3$ seconds, which combined with the high speed of Scud missile led to a serious miscalculation of the flight path.

Details: \url{http://www-users.math.umn.edu/~arnold/disasters/patriot.html}

\paragraph{Ariane 5}
In 1996, the first launch of an Ariane 5 rocket (at a cost of over \$$300$ million for rocket and payload) failed, and the rocket had to be destructed after launch.
Both the primary and the backup system had shut down, each trying to transfer control to the other, after encountering the same behavior, which they interpreted as a hardware error.

The cause was an overflow exception in the alignment system caused by converting a $64$-bit float to a $16$-bit integer, which was not caught and resulted in the display of diagnostic data that the autopilot could not interpret.
The programmers were aware of the problem but had falsely concluded that no conversion check was needed (and therefore omitted the check to speed up processing).
Their conclusion had been made based on Ariane 4 flight data that turned out to be inappropriate for Ariane 5.

The faulty component was not even needed for flight and was only kept active for a brief time after launch for convenience and in order to avoid changing a running system.

Details: \url{http://www-users.math.umn.edu/~arnold/disasters/ariane5rep.html}

\paragraph{Intel Pentium Bug}
In 1994, it was discovered that the Intel Pentium processor (at the time widely used in desktop computers) wrongly computed certain floating point divisions.
The cost of replacing the CPUs was estimated at about \$$400$ million.

The error occurred in about 1 in 9 billion divisions.
For example, $4195835.0/3145727.0$ yielded $1.333 739 068 902 037 589$ instead of $1.333 820 449 136 241 000$.

The cause was a bug in the design of the floating point unit's circuit.

\paragraph{Kerberos Random Number Generator}
From 1988 to 1996, the network authentification protocol Kerberos used a mis-designed random number generation algorithm.
The resulting keys were so predictable that brute force attacks became trivial although it is unclear if the bug was ever exploited.

The cause was the lack of a truly random seed value for the algorithm.
Moreover, the error persisted across attempted fixes because of process failures (code hard to read, programmers had moved on to next version).

Detail: \url{http://docs.lib.purdue.edu/cgi/viewcontent.cgi?article=2331&context=cstech}

\paragraph{USS Yorktown}
In 1997, critical navigation and weapons hardware on the USS Yorktown was paralyzed at sea for $3$ hours while rebooting machines.

The cause was a blank field in a database that was interpreted as $0$ leading to a division-by-zero.
Special floating point values such as infinity or NaN were not used, thus resulting in an exception.
The exception was handled by neither the software nor the operating systems (Windows NT) thus crashing both.

Details: \url{http://www.cs.berkeley.edu/~wkahan/Boulder.pdf}

\paragraph{Mars Climate Orbiter}
In 1998 the Mars Climate Orbiter was lost causing damage of around \$$300$ million after software had calculated a false trajectory when updating the position of the spacecraft.

The cause was that two components by different manufacturers exchanged physical quantities as plain numbers (i.e., without units).
One component assumed customary units (pound seconds) whereas the other assumed SI units (Newton seconds).
The first component was in violation of the specification of the interface.

\paragraph{Year 2000 and 2038 Problems}
Leading to the year 2000, about \$$300$ billion were spent worldwide to update outdated software that was unable to handle dates with a year of $2000$ or higher.

The cause was that much software was used far beyond the originally envisioned lifetime.
At programming time, especially at times when memory was still scarce, it made sense to use only two digits for the year in a date.
That assumption became flawed when dates over $2000$ had to be handled.

A related problem is expected in the year 2038.
At that point the number of seconds since 1970-01-01, which is the dominant way of storing time on Unix, will exceed the capacity of a $32$-bit integer.
While application software is expected to be updated by then anyway, modern embedded systems may or may not still be in use.

\paragraph{Los Angeles Airport Network Outage}
In 2007, LA airport was partially blocked for $10$ hours due to a network outage that prevented passenger processing.
About 17,000 passengers were affected.

The cause was a single network card malfunction that flooded the network and propagated through the local area network.

Details: \url{https://www.oig.dhs.gov/assets/Mgmt/OIGr_08-58_May08.pdf}

\paragraph{Debian OpenSSL Random Number Generator}
From 2006 to 2008 Debian's variant of OpenSSL used a flawed random number generator.
This made the generated keys easily predictable and thus compromised.
It is unclear whether this was exploited.

The cause was that two values were used to obtain random input: the process ID and an uninitialized memory field.
Uninitialized memory should never be used but is sometimes used as a convenient way to cheaply obtain a random number in a low-level programming language like C.
The respective line of code had no immediately obvious purpose because it was not commented.
Therefore, it was removed by one contributor after code analysis tools had detected the use of uninitialized memory and flagged it as a potential bug.

Detail: \url{https://github.com/g0tmi1k/debian-ssh}

\paragraph{Knight Capital Trading Software}
In 2012, high-frequency trading company Knight Capital lost about \$$10$ million per minute for 45 minutes trading on the New York Stock Exchange.

The cause was an undisclosed bug in their automatic trading software.
% http://www.bbc.com/news/magazine-19214294

\paragraph{Heartbleed}
From 2012 to 2014, the OpenSSL library was susceptible to an attack that allowed remotely reading out sections of raw physical memory.
The affected sections were random but repeated attacks could piece together large parts of the memory.
The compromised memory sections could include arbitrary critical data such as passwords or encryption keys.
OpenSSL was used not only by many desktop and server applications but also in portable and embedded devices running Linux.
The upgrade costs are very hard to estimate but were put at multiple \$$100$ millions by some experts.

The cause was a bug in the Heartbeat component, which allowed sending a message to the server, which the server echoed back to test if the connection is alive.
The server code did not check whether the given message length $l$ was actually the length of the message $m$.
Instead, it always returned $l$ bytes starting from the memory address of $m$ even if $l$ was larger than the length of $m$.
This was possible because the used low-level programming language (C) let the programmers store $m$ in a memory buffer and then over-read from that buffer.
Moreover, their C code is so hard to read that it is impossible to notice such minor errors on a cursory inspection.

Details: \url{http://www.theregister.co.uk/2014/04/09/heartbleed_explained/}

\paragraph{Shellshock}
From 1998 to 2014, it was possible for any user to gain root access in the bash shell on Unix-based systems.
The upgrade cost is unknown but was generally small because updates were rolled out within $1$ week of publication.
Moreover, in certain server applications that passed data to bash, clients could execute arbitrary code on the server.

The cause was the use of unvalidated strings to represent complex data.
Bash allowed storing function definitions as environment variables in order to share function definitions across multiple instances.
The content of these environment variables was trusted because function definitions are meant to be side-effect-free.
However, users could append $; C$ to the value of an environment variable defining a function.
When executing this function definition, bash also executed $C$.

%env x='() { :;}; C bash -c :
%means
%x = 'lambda(). : ; C
%and C is also executed (with root privileges)

Independently, many server applications (including the widely used cgi-bin) pass input provided by remote users to bash through environment variables.
This resulted in input provided by remote clients being passed to the bash parser, which was against the assumptions of the parser.
Indeed, several bugs in the bash parser caused remotely exploitable vulnerabilities.

Details: \url{https://fedoramagazine.org/shellshock-how-does-it-actually-work/}

\paragraph{Apple 'goto fail' Bug}
From 2012 to 2014, Apple's iOS SSL/TLS library falsely accepted faulty certificates.
This left most iOS applications susceptible to impersonation or man-in-the-middle attacks.
Because Apple updated the software after detecting the bug, its cost is unclear.

The immediately cause was a falsely-duplicated line of code, which ended the verification of the certificate instead of moving on to the next check.
But a number of insufficiencies in the code and the software engineering process exacerbated the effect of the small bug.

The code was as follows:

\begin{lstlisting}
static OSStatus SSLVerifySignedServerKeyExchange(
  SSLContext *ctx, bool isRsa, SSLBuffer signedParams,
  uint8_t *signature, UInt16 signatureLen)
{
	OSStatus        err;
	...

	if ((err = SSLHashSHA1.update(&hashCtx, &serverRandom)) != 0)
		goto fail;
	if ((err = SSLHashSHA1.update(&hashCtx, &signedParams)) != 0)
		goto fail;
		goto fail;
	if ((err = SSLHashSHA1.final(&hashCtx, &hashOut)) != 0)
		goto fail;
	...

fail:
	SSLFreeBuffer(&signedHashes);
	SSLFreeBuffer(&hashCtx);
	return err;
\end{lstlisting}

In a better programming language that emphasizes the use of high-level data structures, the bug would likely not have happened or be caught easily.
But even using C, it could have been caught by a variety of measures including unreachable code analysis, indentation style analysis, code coverage analysis, unit testing, or coding styles that enforce braces around one-command blocks.
 
Details: \url{https://www.imperialviolet.org/2014/02/22/applebug.html}

\paragraph{Cloudbleed}
In 2017, the web services provider cloudfare accidentally included random memory sections in the pages they served.
This disclosed a large amount of private data.
It is unclear what data exactly.
Because cloudflare hosted so many popular domains, millions of passwords were potentially compromised, affecting almost every internet user in some way.

The problem was a small bug in the HTML parser: one error-generating branch failed to adjust for the case where it happened at the end of the input.
This caused the pointer $n$ to the next character to become one larger than the fixed pointer $l$ to the end of the input buffer.
However, the condition for terminating parsing tested only for $n==l$, not for $n>l$.
This caused a buffer overrun: parsing continued behind the end of the buffer until being terminated or crashing for other reasons.
Because the faulty component performed rewriting HTML on the fly and was designed to be robust against ill-formed HTML, all the data behind the buffer (which in all likelihood was not valid HTML) was simply included without change in the HTML document that was eventually served to the user.

On a higher level, the problem was the wide-spread but well-known to be unsafe use of C-pointers to delimit buffers and of pointer arithmetic to advance pointers in a buffer.

Notably, the fault had been present for a long time but had previously not caused failures because it was so thoroughly tested.
Only when the company started migrating to a new (and better-designed) code base, these faults became active because the old code was temporarily used differently than in the past.

Details: \url{https://blog.cloudflare.com/incident-report-on-memory-leak-caused-by-cloudflare-parser-bug/}

% see also https://www.dwheeler.com/essays/learning-from-disaster.html for heartbleed, shellshock, and goto fail

\section{Other Interesting Failures}

\paragraph{Odyssey Court Software}
In an ongoing crisis since 2016, US county court and California and other states have been having difficulties using the new Odyssey software for recording and disseminating court decisions.
This has caused dozens of human rights violations due to erroneous arrests or imprisonment.
This includes cases where people spent 20 days in jail based on warrants that had already been dismissed.

The cause is a tight staffing situation combined with the switch to a new, more modern software system for recording court decisions.
The new software expects uses more high-level data types (e.g., reference to a law instead of string) in many places.
This has led to the erroneous recording of decisions and a backlog of converting old decisions into the new database (including decisions that invalidate decisions that are already in the database).

Details: \url{https://arstechnica.com/tech-policy/2016/12/court-software-glitches-result-in-erroneous-arrests-defense-lawyers-say/}

\paragraph{Other Failures Caused By System Updates}
This is a selection of failures that did not cause direct damage but led to availability failures on important infrastructure.

In 1990, all AT\&T phone switching centers shut down for 9 hours due to a bug in a software update.
An estimated 75 million phone calls were missed.

In 1999, a faulty software update in the British passport office delayed procedures.
About half a million passports were issued late.

In 2004, the UK's child support agency EDS introduced a software update while restructuring the personnel.
This led to several million people receiving too much or too little money and hundreds of thousands of back-logged cases.

In 2015, the New York Stock Exchange had to pause for $3$ hours for a reboot after a software problem.
700,000 trades had to be canceled.

In 2015, hundreds of flights in the North Eastern US had to be canceled or delayed for several hours.
The cause was a problem with new and behind-schedule computer system installed in air traffic control centers.
% http://www.bbc.com/news/world-us-canada-33950381

\paragraph{FBI Virtual Case File Project}
In 2005 the Virtual Case File project of the FBI, which had been developed since 2000, was scrapped.
The software was never deployed, but the project resulted in the loss of \$$170$ million of development cost.

The cause was systemic failures in the software engineering process including:
\begin{compactitem}
 \item poor specification, which caused bad design decisions
 \item repeated specification changes
 \item repeated change in management
 \item micromanagement of software developers
 \item inclusion of many personnel with little training in computer science in key positions
\end{compactitem}
These problems were exacerbated by the planned flash deployment instead of a gradual phasing-in of the new system---a decision that does have advantages but made the systems difficult to test and made it easier for design flaws to creep in.
The above had two negative effects on the code base
\begin{compactitem}
 \item increasing code size due to changing specifications
 \item increasing scope due to continually added features
\end{compactitem}
which exacerbated the management and programming problems.

\paragraph{Fooling Neural Networks}
Deep learning neural networks have become very popular recently for pattern recognition (pictures and speech in particular).
They are already used in, e.g., in self-driving cars or the AlphaGo system.
Despite their economic importance, they can err spectacularly in ways that are entirely different from the ways human pattern recognition errs.
This is unavoidable because it is a consequence of their mathematical foundations.

Researchers were able to demonstrate that
\begin{compactitem}
 \item minor changes to an image that would be imperceptible to a human can make the network identity as something entirely different (e.g., a lion as a library)
 \item images that are unrecognizable to humans can make the network see an object with absolute certainty (e.g., labeling white noise as a lion)
\end{compactitem}
This has major implications for the safety and security of systems based on these networks.

Details: \url{http://www.evolvingai.org/fooling}

\paragraph{Failures in Machine Learning}
Machine learning systems often learn something other than intended due to modeling failures.
It is generally a dangerous mistake to trust the result of machine learning without carefully analyzing the modeling assumptions.
Lists of failures was compiled in ``The Surprising Creativity of Digital Evolution: A Collection of Anecdotes
from the Evolutionary Computation and Artificial Life Research Communities.'' and ``Specification gaming examples in AI'' (see committed files).

\paragraph{Failures in Cyber-Physical Systems}
The following\footnote{This list was compiled by Sofiene Tahar.} is a list of product recalls caused by software bugs in automotive systems, mostly control software or sensor-control:
\begin{itemize}
\item \url{https://spectrum.ieee.org/riskfactor/computing/software/court-allows-lawsuit-to-proceed-against-fiat-chrysler-over-software-flaw}
\item \url{https://www.popsci.com/software-rising-cause-car-recalls}
\item \url{https://arstechnica.com/tech-policy/2018/05/report-software-bug-led-to-death-in-ubers-self-driving-crash/}
\item \url{https://www.ft.com/content/15e283a0-59eb-11e8-b8b2-d6ceb45fa9d0}
\item \url{http://blog.toyota.co.uk/toyota-announces-voluntary-recall-of-iq-in-the-uk}
\item \url{https://blog.bugfinders.com/lack-of-software-testing-leads-to-spike-in-car-recalls}
\item \url{https://www.wired.com/2015/07/jeep-hack-chrysler-recalls-1-4m-vehicles-bug-fix/}
\item \url{https://www.eetimes.com/document.asp?authorpage=0&authorpage=0&isAjax=true&isAjax=true&doc_id=1323631&_=1535056333785&piddl_msgpage=1#msgs}
\item \url{http://fortune.com/2016/09/09/gm-recall-software/}
\item \url{https://www.reuters.com/article/us-fiatchrysler-recall-idUSKBN1881I6}
\end{itemize}

And here are some in medical systems:
\begin{itemize}
\item \url{https://threatpost.com/fda-software-failures-responsible-24-all-medical-device-recalls-062012/76720/}
\item \url{https://threatpost.com/blind-attack-wireless-insulin-pumps-could-deliver-lethal-dose-102711/75808/}
\end{itemize}

\paragraph{Pixar's Deletion of Toy Story 2}
In 2012, Pixar accidentally deleted almost the entire data for the movie Toy Story 2.
Several weeks of work were lost, and the loss would have been much worse if they had not been able to recover most of the data from one employee's home office computer.

The cause was unclear but assumed to be a human error in the Unix shell that recursively deleted the wrong directory.
Moreover, the backup system had not been tested properly in the recent past.
When the backup was swapped in, it turned out that it was limited to $4$ GB and had become inconsistent when more data than that was written to the drive.

Pixar was able to recover most of the data by manually aggregating and comparing thousands of files from multiple partial copies spread over the various computers of the company.

Details: \url{https://thenextweb.com/media/2012/05/21/how-pixars-toy-story-2-was-deleted-twice-once-by-technology-and-again-for-its-own-good/}

\paragraph{Excel Gene Names}
In 2016, researchers found that about 20\% of papers in genomics journals contain errors in supplementary spreadsheets.

The cause is that Microsoft Excel by default guesses the type of cell data that is entered as a string and converts the string into that type.
This affects gene names like "SEPT2" (Septin 2, converted to the date September 02) or REKIN identifiers like "2310009E13" (converted to the floating point number $2.31E+13$).

Details: \url{https://genomebiology.biomedcentral.com/articles/10.1186/s13059-016-1044-7}

\paragraph{Failures in Involving Computer-Related Manufacturing}
This is a selection of other notable failures that involve hardware manufacturing.

In 2006, two Airbus plants used incompatible version of CAD software.
This resulted in cables being produced too short to connect.

In 2006, Sony batteries mostly used in Dell notebooks had to be recalled.
The resulting cost was about \$$100$ million.

In 2016, Samsung Galaxy phones had to be recalled due to faulty batteries.

\section{Major Vulnerabilities due to Weak Security}

\subsection{Software and Internet}

\paragraph{Operating Systems}
Vulnerabilities in operating systems are dangerous because only a few systems are used worldwide, therefore any problem is shared by many users.
Moreover, the operating system usually has full access to the computer and its network, which allows any attack to do great damage.

Moreover, operating systems are usually bundled with standard applications (e.g., web browser, email viewer).
These are tightly integrated with the OS (e.g., by using the same libraries for encryption or accessing files).
Thus, a vulnerability often badly affects the majority of users who use these standard applications.

In 2000, the ILOVEYOU worm exploited weaknesses in the Windows OS and Outlook mail service, by infecting a significant share of all internet-connected computers within a few days.
Its damage was estimated at over \$$5$ billion and the removal costs at over \$$410$ billion.

In recent years operating system companies have reacted to these problems.
They have become more sensitive to security issues and allow for coordinated disclosure of vulnerabilities together with swift updates.
Most noticeable for end users is the urged tendency to frequently install updates.
For example,
\begin{compactitem}
\item Microsoft Windows 10 automatically downloads and installs updates in a way that users cannot prevent.
\item Google's Android now reserves the right to download minor updates immediately, even via mobile data.
\end{compactitem}
This has greatly reduced the frequency of major problems.

An additional problem is that attacks are often conducted by state governments for purposes of terrorism, oppresion, espionage, sabotage, or law enforcement.

In 2010, the stuxnet worm was used by presumably the US and/or Israel to sabotage Iran's nuclear program.
It was the most sophisticated attack to become public, involving multiple zero-day exploits and including attacks on programmable logic controllers.

In 2013, Edward Snowden revealed a massive secret surveillance program run by the US government.
It used many ways to intercept data sent by users either at transmission nodes or at company data centers.
This included connection metadata and any unencrypted or decryptable content.
The stolen data remains mostly secret so that it prevents clarity on the information compromised and its usage.
In response, many software companies introduced end-to-end encryption that precludes even themselves to access their users data.

In 2016, Citizen Lab discovered an attack that used previously unknown vulnerabilities in Apple's Safari on iOS.
It allowed, for the first time, an attacker to remotely take full control of the iPhone, triggered as soon as Safari was pointed to the attack URL.
It is suspected that the exploit was produced commercially by the Israeli company NSO Group and used (at least) by the United Arab Emirates to spy on dissidents.

Details: \url{http://www.vanityfair.com/news/2016/11/how-bill-marczak-spyware-can-control-the-iphone}

\paragraph{Cloud Services}
Consumers are more and more using internet services for their processing needs.
These include
\begin{compactitem}
\item file storage, e.g., via Dropbox
\item email and calendar services, e.g., via gmail
\item office applications, e.g., directly via Google's office web site or indirectly via Microsoft's office suite
\item social networking, e.g., via Facebook
\end{compactitem}
Most modern operating systems and their bundled applications store large amounts of user data on the company's web servers, including, e.g., message archive, photographs, or location history.
This creates unprecented risks for privacy, with legal regulation mostly lagging behind.
(Most legislation were designed to limit the government from violating privacy.
Corporations were barely restricted, in fact they used to have less power.)

Because most users do not understand the technical issues and blindly accept terms of service, thus generously granting access rights to applications, more and more user data becomes available to the free market.
This is used for both legitimate (e.g., advertising-financed free services) or questionable purposes (e.g., manipulating voter preferences through personalized messages).

In 2014, The Fappening was an attack that combined phishing and password-guessing to gain access to many user accounts on Apple's iCloud.
These acounts included, among other things, backups of all photographs taken with iPhones.
Among the private data stolen and published were hundreds of nude pictures of celebrities.

\paragraph{Large Institutions}
In 2014, Sony Pictures suffered a major break-in (possibly by North Korea to blackmail or punish Sony in relation to the movie \emph{The Interview}) mostly facilitated by unprecedented negligence.
Problems included
\begin{compactitem}
 \item unencrypted storage of sensitive information
 \item password stored in plain text files (sometimes even called ``passwords'' or placed in the same directory as encrypted files)
 \item easily guessable passwords
 \item large number of unmonitored devices
 \item lack of accountability and responsibility for security, ignorance towards recommendations and audits
 \item lack of systematic lesson-learning from previous failures (which included 2011 hacks of Sony PlayStation Network and Sony Pictures that stole account information including unsalted or plain text passwords)
 \item weak IT and information security teams
\end{compactitem}
Stolen data included employee data (including financial data), internal emails, and movies.
\medskip

In 2016, the US democratic party's headquarters suffered a break-in (possibly by Russia to manipulate or discredit that year's presidential election).
The stolen data included in particular internal emails and personal data of donors.
Especially, the former hurt the public perception of the party's campaign to an unknown degree that may or may not have been decisive.

\paragraph{User Account Data}
Many organizations holding user data employ insufficient security against digital break-ins and insufficient (if any) encryption of user data.
They get hacked or otherwise compromised so routinely that a strong market for stolen identities has developed, often pricing bulk datasets at a few dollars per identity.
Overviews can be found at \url{https://haveibeenpwned.com/} or \url{https://en.wikipedia.org/wiki/SQL_injection}.

This development is exacerbated by two human problems:
\begin{compactitem}
 \item System administrators are not sufficiently educated about password hashing and often falsely believe default hash configurations to be secure.
 Thus, hacks often allow inverting the hash function thus exposing passwords in addition to the possibly sensitive user data.
 \item Users are not sufficiently educated about systematically using different passwords on every site.
 Thus, any breach also compromises accounts on any other sites that use the same user name or email address and password.
\end{compactitem}

Many websites now offer and nudge users to use two-factor authentication to protect accounts from identity theft.
A second factor (e.g., via email or text message) may be required for every login, for every login from a new location, or for every sensitive action like changing the password.
Security questions, which are particularly vulnerable, are phased out by leading companies.
But both websites and users are slow to get used to this.
\medskip

This problem is exacerbated by wide-ranging technically legal access by government agencies to private data.
Companies usually comply with subpoenas by the country they operate in (both democracies and others) even if that compromises private user data.
For example, in 2017, a US court decided that US companies (i.e., the majority of companies holding sensitive user data) must, if subpoenaed, hand over to US government also all user data stored on servers abroad.
That makes it very difficult for other countries to enforce stricter data protection laws.

These constraints interact with market forces and foreign and economic policy.
For example, China uses a protectionist policy to strengthen Chinese alternatives to US web services like Google or Facebook.
But they also allow foreign companies under the condition that they provide the Chinese government with strong access to private data.
Complying with these rules opens Western web service providers up to accusations that they support human rights violations.
But dismissing these market opportunities opens them up to competition and shareholder pressure.
\medskip

The following describes a few high-profile cases of stolen user data:
\begin{compactitem}
\item In a 2005 hack of the US credit card payment processing company CardSystems, over $40$ million accounts were compromised.
The stolen data included name and credit card number.
The reason was an SQL injection attack.

\item In a 2005/2006 hack (reported in 2007) of the US retailer TJX, about $45$ million accounts were compromised with an estimated damage of \$$1$ billion.
The stolen data included name and credit card number.
The cause was the use of the obsolete WEP security standard for communication between pricing devices in one store.
This allowed hackers to access the central database, where data was stored unencrypted that should have been deleted.

\item In a (estimated) 2008 (only reported in 2016) of myspace, about $360$ million accounts were compromised.
The stolen data included user name, email address, and badly hashed passwords (unsalted SHA1).

\item In a 2012 hack of linkedin, $160$ million accounts were compromised.
The stolen data included user name, email address, and badly hashed passwords (unsalted SHA1).

\item In 2014, data for over $1$ billion accounts from $420,000$ websites were discovered by the security company Hold Security.
It is claimed that many of these break-ins stems from bot carrying out SQL injection attacks.
The details are unclear as some claims by Hold Security are disputed.

\item In a 2015 hack of Ashley Madison, about $30$ million accounts were compromised.
The stolen records included name, email address, hashed password, physical description, and sexual preferences.
Most passwords were hashed securely (using bcrypt for salting and stretching), but about $10$ million passwords were hashed insecurely (using a single MD5 application).
This led to multiple extortion attempts and possibly suicides.
% https://nakedsecurity.sophos.com/2015/09/10/11-million-ashley-madison-passwords-cracked-in-10-days/

\item In a 2016 hack of the Friend Finder network, about $400$ million accounts were compromised.
The stolen records included name, email address, registration date, and unhashed or badly hashed passwords.
% https://www.leakedsource.com

\item In two separate hacks in 2013 (only reported in 2016) and 2014 of Yahoo, over $1$ billion user accounts were compromised by presumably Russia-sponsored actors.
The stolen records included name, email address, phone number, date of birth, and hashed passwords, and in some cases security questions and answers.
\end{compactitem}

\subsection{Dedicated Systems}

Many domains are increasingly using computer technology.
Often this is done by engineers with little training in computer science and even less training in security aspects.
In many cases, the resulting systems are highly susceptible to attacks, spared only by the priorities of potential hackers and terrorists.

\paragraph{Embedded Systems}
Embedded systems are increasingly running high-level operating systems, typically variants of Linux or Windows, and software.
They are particularly vulnerable due to a number of systemic flaws:
\begin{compactitem}
\item Software often cannot be updated at all or not conveniently. Thus, they collect many security vulnerabilities over time.
\item Affected devices may be in use for years or decades, thus accumulating many vulnerabilities.
\item It is hard or impossible for users to interact with the software in a way that would allow them to understand or patch its vulnerabilities.
\item Access is often not secured or not secured well.
Often master passwords (possibly the same on every instance of the system and possibly hard-coded) are used to allow access for technicians.
\item It is often difficult to list all access rights (e.g., of remote control access via smartphone) or to revoke some of them (e.g., of previous owners).
\end{compactitem}

% https://motherboard.vice.com/en_us/article/this-teen-hacked-150000-printers-to-show-how-the-internet-of-things-is-shit?utm_source=mbnl

\paragraph{Cars}
The upcoming wave of self-driving cars requires the heavy use of experienced software developers and a thorough regulation process.
It is therefore reasonable to hope that security will play a major role in the design and legal regulation.

But even today's traditional cars are susceptible to attacks including remote takeover of locks, wheels, or engine.
The causes are
\begin{compactitem}
 \item not or not properly protected physical interfaces for diagnostics and repair,
 \item permanent internet connections, which are useful for navigation and entertainment, that are not strictly separated from engine controls.
\end{compactitem}
One of the more high-profile benevolent attack demonstrations was described in \url{https://www.wired.com/2015/07/hackers-remotely-kill-jeep-highway/}.

\paragraph{Medical Systems}
Hospitals and manufacturers of medical devices are notoriously easy to hack.

Weaknesses include unchangeable master passwords, unencrypted communication between devices, outdated and non-updateable software running in devices, and outdated or non-existent protection against attackers.
Systemic causes include a highly-regulated release process that precludes fast patching of software and a slow update cycle.

Details:
\url{http://cacm.acm.org/magazines/2015/4/184691-security-challenges-for-medical-devices/fulltext}

See also the Symantec 2016 Healthcare Internet Security Threat Report available at \url{https://www.symantec.com/solutions/healthcare}

%\subsection{Public Processes}
 % digital signatures
 % elections
